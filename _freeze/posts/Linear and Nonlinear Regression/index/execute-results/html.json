{
  "hash": "6f6371ae2e07d3939de1952e7a62e71e",
  "result": {
    "markdown": "---\ntitle: \"Linear and NonLinear Regression\"\ntitle-block-banner: true\ndescription: \"Theory on Linear and Non linear regression and an example of linear regression model.\"\ncategories: [Linear Regression, Supervised Learning]\nauthor: \"Akash Mittal\"\ndate: \"11/17/2023\"\n---\n\n### Introduction to Linear Regression\n\nLinear regression is a supervised learning algorithm used for predicting a continuous outcome variable (also called the dependent variable) based on one or more predictor variables (independent variables). There is an assumption of a linear relation between the independent predictor variables and the dependent outcome variables. \n\nIt can be mathematically represented as follows:\n\n$Y = \\mathcal{B}_0 + \\mathcal{B}_1X_1 +\\mathcal{B}_2X_2 + \\mathcal{B}_3X_3 + ... + \\mathcal{B}_nX_n + \\epsilon$ \n\nwhere Y is the predicted outcome, $X_1$, $X_2$, ..., $X_n$ are predictor variables, $\\mathcal{B}_0, \\mathcal{B}_1, \\mathcal{B}_2, \\ldots , \\mathcal{B}_n$ are weights associated to each predicted variables and $\\epsilon$ is the error term. \n\nThe goal is to find all $\\mathcal{B}_0, \\mathcal{B}_1, \\mathcal{B}_2, \\ldots , \\mathcal{B}_n$ that minimize the sum of squared differences between the predicted and actual values (least squares method).\n\nA few assumptions in linear regression other than the linear relationship are the following:\n\n1. Linear Regression assumes that the residuals (the differences between predicted and actual values) are normally distributed\n\n2. The residuals should have constant variance (homoscedasticity).\n\n3. There should be little or no multicollinearity (high correlation) among the predictor variables.\n\n### Introduction to NonLinear Regression\nThe relationship between the relationship between the dependent variable and the independent variables is modeled using a nonlinear function. \n\nThis can be mathematically represented as following:\n\n$Y = f(X, \\mathcal{B}) +\\epsilon$\n\nSimilar to linear regression, the objective in nonlinear regression is often to minimize the difference between the predicted values from the model and the actual observed values. Also evaluation metrics for nonlinear regression are similar to those used in linear regression, such as Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE) and etc. \n\nSome Types of NonLinear relationships can be the following:\n\n1. Quadratic \n\n2. Logarithmic \n\n3. Exponential\n\n### Example of Linear Regression\nFor this examples we will look real estate houses and their prices, one of the quintessential applications of Linear Regression. The goal is to predict the price of a house based on some features of a house. This data is a dataset taken from Kaggle as toy example to show this concept.\n\n**Loading the Dataset**\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\n%matplotlib inline\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nUSAhousing = pd.read_csv('USA_Housing.csv')\nUSAhousing.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Avg. Area Income</th>\n      <th>Avg. Area House Age</th>\n      <th>Avg. Area Number of Rooms</th>\n      <th>Avg. Area Number of Bedrooms</th>\n      <th>Area Population</th>\n      <th>Price</th>\n      <th>Address</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>79545.458574</td>\n      <td>5.682861</td>\n      <td>7.009188</td>\n      <td>4.09</td>\n      <td>23086.800503</td>\n      <td>1.059034e+06</td>\n      <td>208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>79248.642455</td>\n      <td>6.002900</td>\n      <td>6.730821</td>\n      <td>3.09</td>\n      <td>40173.072174</td>\n      <td>1.505891e+06</td>\n      <td>188 Johnson Views Suite 079\\nLake Kathleen, CA...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>61287.067179</td>\n      <td>5.865890</td>\n      <td>8.512727</td>\n      <td>5.13</td>\n      <td>36882.159400</td>\n      <td>1.058988e+06</td>\n      <td>9127 Elizabeth Stravenue\\nDanieltown, WI 06482...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>63345.240046</td>\n      <td>7.188236</td>\n      <td>5.586729</td>\n      <td>3.26</td>\n      <td>34310.242831</td>\n      <td>1.260617e+06</td>\n      <td>USS Barnett\\nFPO AP 44820</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59982.197226</td>\n      <td>5.040555</td>\n      <td>7.839388</td>\n      <td>4.23</td>\n      <td>26354.109472</td>\n      <td>6.309435e+05</td>\n      <td>USNS Raymond\\nFPO AE 09386</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n**Visualizing the data (which factors are linearly related to Price**\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nsns.pairplot(USAhousing, y_vars = 'Price')\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.png){width=1417 height=241}\n:::\n:::\n\n\n**Training Linear Regression Model**\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nX = USAhousing[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms', 'Avg. Area Number of Bedrooms', 'Area Population']]\ny = USAhousing['Price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 101)\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n```\n:::\n\n\n**Model Evaluation - The weights associated to the features**\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nprint(lm.intercept_)\ncoeff_df = pd.DataFrame(lm.coef_, X.columns,columns=['Coefficent'])\ncoeff_df\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-2640159.796851912\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Coefficent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Avg. Area Income</th>\n      <td>21.528276</td>\n    </tr>\n    <tr>\n      <th>Avg. Area House Age</th>\n      <td>164883.282027</td>\n    </tr>\n    <tr>\n      <th>Avg. Area Number of Rooms</th>\n      <td>122368.678027</td>\n    </tr>\n    <tr>\n      <th>Avg. Area Number of Bedrooms</th>\n      <td>2233.801864</td>\n    </tr>\n    <tr>\n      <th>Area Population</th>\n      <td>15.150420</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n**Predictions from the Model**\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\npredictions = lm.predict(X_test)\nplt.scatter(y_test,predictions)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n<matplotlib.collections.PathCollection at 0x147c2c3a0>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-2.png){width=571 height=442}\n:::\n:::\n\n\n**Metrics to Evaluate the Model**\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nprint('Mean Squared Error = ', metrics.mean_squared_error(y_test,predictions))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean Squared Error =  10460958907.2095\n```\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}